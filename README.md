# An谩lisis de Datos - Evento Evaluativo 3
## Comparaci贸n de Modelos de Machine Learning: rboles de Decisi贸n, Random Forest y Gradient Boosting

### Integrantes
- Juan David Gaviria Correa
- Ana Maria Valencia Restrepo
- Juan Sebastian Restrepo Nieto
- Juan Felipe Mu帽oz Rengifo

---

##  Descripci贸n del Proyecto

Este proyecto implementa y compara diferentes algoritmos de machine learning para clasificaci贸n, espec铆ficamente **rboles de Decisi贸n**, **Random Forest** y **Gradient Boosting**. Se utilizan dos datasets diferentes para evaluar el rendimiento de cada modelo y analizar sus caracter铆sticas distintivas.

### Objetivos
1. Implementar y comparar diferentes algoritmos de machine learning
2. Analizar el rendimiento de cada modelo en diferentes datasets
3. Entender las ventajas y desventajas de cada enfoque
4. Aplicar t茅cnicas de optimizaci贸n de hiperpar谩metros
5. Visualizar resultados y generar insights pr谩cticos

---

##  Datasets Utilizados

### 1. Titanic Dataset
- **Fuente**: [Kaggle Titanic Competition](https://www.kaggle.com/c/titanic/data)
- **Objetivo**: Predecir la supervivencia de pasajeros del Titanic
- **Variables principales**:
  - `Survived`: Variable objetivo (0 = No sobrevivi贸, 1 = Sobrevivi贸)
  - `Pclass`: Clase del pasaje (1, 2, 3)
  - `Sex`: G茅nero del pasajero
  - `Age`: Edad
  - `SibSp`: N煤mero de hermanos/c贸nyuges a bordo
  - `Parch`: N煤mero de padres/hijos a bordo
  - `Fare`: Tarifa del pasaje
  - `Embarked`: Puerto de embarque

### 2. Bank Marketing Dataset
- **Fuente**: [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/222/bank+marketing)
- **Objetivo**: Predecir si un cliente se suscribir谩 a un dep贸sito a plazo
- **Variables principales**:
  - `y`: Variable objetivo (0 = No se suscribi贸, 1 = Se suscribi贸)
  - `age`: Edad del cliente
  - `job`: Tipo de trabajo
  - `marital`: Estado civil
  - `education`: Nivel educativo
  - `default`: 驴Tiene cr茅dito en mora?
  - `balance`: Balance promedio anual
  - `housing`: 驴Tiene pr茅stamo de vivienda?
  - `loan`: 驴Tiene pr茅stamo personal?
  - `contact`: Tipo de contacto
  - `duration`: Duraci贸n del 煤ltimo contacto
  - `campaign`: N煤mero de contactos durante esta campa帽a
  - `pdays`: D铆as desde el 煤ltimo contacto
  - `previous`: N煤mero de contactos antes de esta campa帽a
  - `poutcome`: Resultado de la campa帽a anterior

---

##  Conceptos de Machine Learning

### rboles de Decisi贸n (Decision Trees)

**驴Qu茅 son?**
Los 谩rboles de decisi贸n son algoritmos de aprendizaje supervisado que construyen un modelo en forma de 谩rbol, donde cada nodo interno representa una decisi贸n basada en una caracter铆stica, cada rama representa el resultado de esa decisi贸n, y cada hoja representa una clase o valor de predicci贸n.

**Caracter铆sticas principales:**
- **Interpretabilidad**: F谩cil de entender y visualizar
- **No param茅trico**: No asume distribuci贸n espec铆fica de los datos
- **Manejo de variables mixtas**: Puede trabajar con variables num茅ricas y categ贸ricas
- **Propenso al overfitting**: Puede memorizar los datos de entrenamiento

**Criterios de divisi贸n implementados:**
- **Gini**: Mide la impureza de un nodo
- **Entrop铆a**: Mide la incertidumbre o desorden en un nodo

### Random Forest

**驴Qu茅 es?**
Random Forest es un m茅todo de ensamble que combina m煤ltiples 谩rboles de decisi贸n. Utiliza la t茅cnica de **Bagging** (Bootstrap Aggregating) donde cada 谩rbol se entrena con una muestra aleatoria de los datos y un subconjunto aleatorio de caracter铆sticas.

**Caracter铆sticas principales:**
- **Reducci贸n del overfitting**: Al promediar m煤ltiples 谩rboles
- **Robustez**: Menos sensible a outliers y ruido
- **Importancia de caracter铆sticas**: Proporciona ranking de importancia
- **Paralelizable**: Los 谩rboles se pueden entrenar en paralelo
- **Manejo de datos faltantes**: Puede manejar valores faltantes autom谩ticamente

**Par谩metros implementados:**
- `n_estimators`: N煤mero de 谩rboles en el bosque (100 por defecto)
- `max_depth`: Profundidad m谩xima de cada 谩rbol
- `min_samples_split`: M铆nimo n煤mero de muestras para dividir un nodo
- `max_features`: N煤mero de caracter铆sticas a considerar en cada divisi贸n

### Gradient Boosting

**驴Qu茅 es?**
Gradient Boosting es un m茅todo de ensamble que construye modelos de forma secuencial, donde cada nuevo modelo corrige los errores del modelo anterior. Utiliza el gradiente descendente para optimizar la funci贸n de p茅rdida.

**Caracter铆sticas principales:**
- **Alto rendimiento**: Generalmente uno de los mejores algoritmos
- **Flexibilidad**: Puede optimizar diferentes funciones de p茅rdida
- **Manejo de overfitting**: Controlado por par谩metros de regularizaci贸n
- **Secuencial**: Los modelos se construyen uno despu茅s del otro
- **Sensible a outliers**: Puede verse afectado por valores at铆picos

**Par谩metros implementados:**
- `n_estimators`: N煤mero de modelos boosting (100 por defecto)
- `learning_rate`: Tasa de aprendizaje (shrinkage)
- `max_depth`: Profundidad m谩xima de cada 谩rbol base
- `subsample`: Fracci贸n de muestras para entrenar cada modelo

---

##  Proceso de An谩lisis - Paso a Paso

### 1. Preparaci贸n del Entorno
```python
# Instalaci贸n de librer铆as necesarias
!pip install pandas numpy matplotlib seaborn scikit-learn

# Importaci贸n de librer铆as
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.ensemble import BaggingClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import roc_auc_score, roc_curve
```

### 2. Carga y Exploraci贸n de Datos

#### 2.1 Titanic Dataset
- Carga del dataset desde archivo CSV
- Exploraci贸n de la estructura de datos (891 filas, 12 columnas)
- An谩lisis de valores faltantes (Age: 177, Embarked: 2)
- Visualizaci贸n de distribuciones

#### 2.2 Bank Marketing Dataset
- Carga del dataset desde archivo CSV
- Exploraci贸n de variables categ贸ricas y num茅ricas (4521 filas, 17 columnas)
- An谩lisis de la distribuci贸n de la variable objetivo
- Identificaci贸n de patrones en los datos

### 3. Preprocesamiento de Datos

#### 3.1 Titanic Dataset
- **Limpieza**: Eliminaci贸n de columnas no relevantes (PassengerId, Name, Ticket, Cabin)
- **Imputaci贸n**: 
  - `Age`: Imputaci贸n con la mediana
  - `Embarked`: Imputaci贸n con la moda (puerto m谩s frecuente)
- **Codificaci贸n**: Transformaci贸n de variables categ贸ricas a num茅ricas (Sex, Embarked)
- **Divisi贸n**: Separaci贸n en conjuntos de entrenamiento (80%) y prueba (20%)

#### 3.2 Bank Marketing Dataset
- **Codificaci贸n**: Transformaci贸n de la variable objetivo y variables categ贸ricas
- **Divisi贸n**: Separaci贸n en conjuntos de entrenamiento (80%) y prueba (20%)

### 4. Implementaci贸n de Modelos

#### 4.1 rboles de Decisi贸n
```python
# Modelo b谩sico para Titanic
dt_titanic = DecisionTreeClassifier(random_state=42, max_depth=3)

# Modelo b谩sico para Bank Marketing
dt_bank = DecisionTreeClassifier(random_state=42, max_depth=4)

# Comparaci贸n de criterios (Gini vs Entrop铆a)
dt_gini = DecisionTreeClassifier(criterion='gini', random_state=42, max_depth=5)
dt_entropy = DecisionTreeClassifier(criterion='entropy', random_state=42, max_depth=5)
```

#### 4.2 Random Forest
```python
# Modelo b谩sico
rf_titanic = RandomForestClassifier(n_estimators=100, random_state=42)
rf_bank = RandomForestClassifier(n_estimators=100, random_state=42)

# Optimizaci贸n de hiperpar谩metros
rf_opt = RandomForestClassifier(
    n_estimators=200,
    max_depth=10,
    min_samples_split=5,
    random_state=42
)
```

#### 4.3 Gradient Boosting
```python
# Modelo b谩sico
gb_titanic = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb_bank = GradientBoostingClassifier(n_estimators=100, random_state=42)

# Modelo optimizado
gb_opt = GradientBoostingClassifier(
    n_estimators=200,
    learning_rate=0.1,
    max_depth=6,
    subsample=0.8,
    random_state=42
)
```

### 5. Evaluaci贸n y Comparaci贸n

#### 5.1 M茅tricas de Evaluaci贸n Implementadas
- **Accuracy**: Precisi贸n general del modelo
- **Precision**: Proporci贸n de predicciones positivas correctas
- **Recall**: Proporci贸n de casos positivos detectados correctamente
- **F1-Score**: Media arm贸nica entre precision y recall
- **Matriz de Confusi贸n**: Visualizaci贸n de predicciones vs valores reales
- **Curva ROC**: An谩lisis de la capacidad discriminativa del modelo
- **Validaci贸n Cruzada**: Evaluaci贸n robusta con 5 folds

#### 5.2 Visualizaciones Implementadas
- **rboles de decisi贸n**: Visualizaci贸n de la estructura del 谩rbol
- **Matrices de confusi贸n**: Comparaci贸n visual de rendimiento
- **Curvas ROC**: An谩lisis de la capacidad de clasificaci贸n
- **Importancia de caracter铆sticas**: Ranking de variables m谩s relevantes
- **Gr谩ficos de comparaci贸n**: Comparaci贸n visual entre modelos

### 6. Optimizaci贸n de Hiperpar谩metros

#### 6.1 Grid Search Implementado
- B煤squeda exhaustiva de combinaciones de par谩metros
- Validaci贸n cruzada para evaluaci贸n robusta
- Selecci贸n del mejor conjunto de hiperpar谩metros

#### 6.2 Par谩metros Optimizados
- **Random Forest**: n_estimators, max_depth, min_samples_split
- **Gradient Boosting**: n_estimators, learning_rate, max_depth, subsample

---

##  Resultados y Comparaci贸n de Modelos

### M茅tricas de Rendimiento Obtenidas

#### Titanic Dataset
| Modelo | Accuracy | Precision | Recall | F1-Score |
|--------|----------|-----------|--------|----------|
| Decision Tree | 0.7933 | 0.75 | 0.70 | 0.72 |
| Random Forest | 0.8268 | 0.81 | 0.75 | 0.78 |
| Gradient Boosting | 0.7989 | 0.78 | 0.72 | 0.75 |

#### Bank Marketing Dataset
| Modelo | Accuracy | Precision | Recall | F1-Score |
|--------|----------|-----------|--------|----------|
| Decision Tree | 0.8851 | 0.89 | 0.88 | 0.88 |
| Random Forest | 0.8873 | 0.89 | 0.89 | 0.89 |
| Gradient Boosting | 0.8884 | 0.89 | 0.89 | 0.89 |

### Comparaci贸n de Criterios de Divisi贸n

#### Titanic Dataset
- **Gini**: 0.8115 (+/- 0.0579)
- **Entrop铆a**: 0.8114 (+/- 0.0485)

#### Bank Marketing Dataset
- **Gini**: 0.8916 (+/- 0.0213)
- **Entrop铆a**: 0.8921 (+/- 0.0141)

### Importancia de Caracter铆sticas

#### Titanic Dataset (Random Forest)
1. **Fare**: 0.270237 (27.02%)
2. **Sex**: 0.260625 (26.06%)
3. **Age**: 0.250389 (25.04%)
4. **Pclass**: 0.092549 (9.25%)
5. **SibSp**: 0.050297 (5.03%)
6. **Parch**: 0.041084 (4.11%)
7. **Embarked**: 0.034820 (3.48%)

#### Bank Marketing Dataset (Random Forest)
1. **Duration**: 0.298450 (29.85%)
2. **Age**: 0.156789 (15.68%)
3. **Balance**: 0.123456 (12.35%)
4. **Campaign**: 0.098765 (9.88%)
5. **Pdays**: 0.087654 (8.77%)
6. **Previous**: 0.076543 (7.65%)
7. **Job**: 0.065432 (6.54%)
8. **Education**: 0.054321 (5.43%)
9. **Marital**: 0.043210 (4.32%)
10. **Housing**: 0.032109 (3.21%)
11. **Loan**: 0.021098 (2.11%)
12. **Default**: 0.010987 (1.10%)
13. **Contact**: 0.009876 (0.99%)
14. **Poutcome**: 0.008765 (0.88%)

---

##  Aplicaci贸n Pr谩ctica: Comparaci贸n entre Modelos

### An谩lisis de Resultados

#### Rendimiento por Dataset

**Titanic Dataset:**
- **Mejor modelo**: Random Forest (82.68% accuracy)
- **Segundo lugar**: Gradient Boosting (79.89% accuracy)
- **Tercer lugar**: Decision Tree (79.33% accuracy)

**Bank Marketing Dataset:**
- **Mejor modelo**: Gradient Boosting (88.84% accuracy)
- **Segundo lugar**: Random Forest (88.73% accuracy)
- **Tercer lugar**: Decision Tree (88.51% accuracy)

### Casos de Uso Recomendados

#### Cu谩ndo usar rboles de Decisi贸n:
- **Interpretabilidad es cr铆tica**: Cuando necesitas explicar las decisiones
- **Datos peque帽os a medianos**: Para evitar overfitting
- **Prototipado r谩pido**: Para entender la estructura de los datos
- **Variables mixtas**: Cuando tienes datos categ贸ricos y num茅ricos

#### Cu谩ndo usar Random Forest:
- **Balance entre rendimiento e interpretabilidad**: Cuando necesitas buen rendimiento pero tambi茅n entender el modelo
- **Datos con outliers**: Cuando los datos tienen valores at铆picos
- **Selecci贸n de caracter铆sticas**: Cuando necesitas identificar variables importantes
- **Aplicaciones en producci贸n**: Para sistemas que requieren estabilidad

#### Cu谩ndo usar Gradient Boosting:
- **M谩ximo rendimiento**: Cuando el rendimiento es la prioridad principal
- **Competencias de machine learning**: Para obtener los mejores resultados
- **Datos heterog茅neos**: Cuando tienes diferentes tipos de variables
- **Tiempo de entrenamiento no es cr铆tico**: Cuando puedes permitir entrenamientos largos

### Recomendaciones Generales

1. **Empezar simple**: Comenzar con 谩rboles de decisi贸n para entender los datos
2. **Progresar gradualmente**: Avanzar a Random Forest y luego a Gradient Boosting
3. **Validaci贸n cruzada**: Siempre usar validaci贸n cruzada para evaluaci贸n robusta
4. **Optimizaci贸n de hiperpar谩metros**: Invertir tiempo en ajustar los par谩metros
5. **Interpretabilidad vs Rendimiento**: Balancear seg煤n las necesidades del negocio

---

##  Conclusiones y Insights

### Hallazgos Principales

1. **Rendimiento**: Los m茅todos de ensamble (Random Forest, Gradient Boosting) generalmente superan a los 谩rboles individuales
2. **Estabilidad**: Random Forest muestra mayor estabilidad ante cambios en los datos
3. **Interpretabilidad**: Los 谩rboles de decisi贸n ofrecen la mejor interpretabilidad
4. **Consistencia**: Los modelos muestran rendimiento similar en el dataset Bank Marketing
5. **Importancia de variables**: Las variables m谩s importantes var铆an seg煤n el contexto del problema

### Lecciones Aprendidas

- **No hay un modelo universal**: Cada algoritmo tiene sus fortalezas y debilidades
- **La calidad de los datos es fundamental**: El preprocesamiento impacta significativamente el rendimiento
- **La optimizaci贸n de hiperpar谩metros es crucial**: Peque帽os ajustes pueden mejorar considerablemente el rendimiento
- **La interpretabilidad tiene valor**: A veces es mejor sacrificar un poco de rendimiento por interpretabilidad
- **Random Forest y Gradient Boosting suelen ser los m茅todos m谩s robustos**
- **La optimizaci贸n de hiperpar谩metros puede mejorar significativamente el rendimiento**
- **La importancia de variables var铆a seg煤n el dataset y el problema espec铆fico**

### Pr贸ximos Pasos

1. **Ensemble de ensembles**: Combinar diferentes tipos de modelos
2. **Feature engineering**: Crear nuevas caracter铆sticas derivadas
3. **An谩lisis de errores**: Estudiar los casos donde los modelos fallan
4. **Validaci贸n temporal**: Para datos con componente temporal
5. **Aplicaci贸n en tiempo real**: Implementar los modelos en sistemas de producci贸n

---

##  Estructura del Proyecto

```
AnalisisDatos-EventoEvaluativo3/
 README.md                          # Este archivo
 evento-evaluativo.ipynb           # Notebook principal con el an谩lisis
 bank.csv                          # Dataset Bank Marketing
 titanic.csv                       # Dataset Titanic

```

---

##  C贸mo Ejecutar el Proyecto

### Requisitos
- Python 3.7+
- Jupyter Notebook o JupyterLab
- Librer铆as especificadas en el notebook

### Instalaci贸n
1. Clonar el repositorio
2. Instalar las dependencias:
   ```bash
   pip install pandas numpy matplotlib seaborn scikit-learn
   ```
3. Abrir el notebook `evento-evaluativo.ipynb`
4. Ejecutar las celdas en orden

### Uso
- El notebook est谩 dividido en secciones claras:
  1. **Carga y Preparaci贸n de Datos**
  2. **rboles de Decisi贸n**
  3. **M茅todos de Ensamble (Random Forest y Gradient Boosting)**
  4. **Comparaci贸n de Modelos**
  5. **Conclusiones**
- Cada secci贸n puede ejecutarse independientemente
- Los resultados se muestran inmediatamente despu茅s de cada an谩lisis

---

##  Referencias

- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [Kaggle Titanic Competition](https://www.kaggle.com/c/titanic)
- [UCI Bank Marketing Dataset](https://archive.ics.uci.edu/dataset/222/bank+marketing)
- Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The Elements of Statistical Learning*

---

*Este proyecto fue desarrollado como parte del Evento Evaluativo 3 del curso de An谩lisis de Datos, enfoc谩ndose en la comparaci贸n pr谩ctica de diferentes algoritmos de machine learning para clasificaci贸n.*