# An√°lisis de Datos - Evento Evaluativo 3
## Comparaci√≥n de Modelos de Machine Learning: √Årboles de Decisi√≥n, Random Forest y Gradient Boosting

### Integrantes
- Juan David Gaviria Correa
- Ana Maria Valencia Restrepo
- Juan Sebastian Restrepo Nieto
- Juan Felipe Mu√±oz Rengifo

---

## üìã Descripci√≥n del Proyecto

Este proyecto implementa y compara diferentes algoritmos de machine learning para clasificaci√≥n, espec√≠ficamente **√Årboles de Decisi√≥n**, **Random Forest** y **Gradient Boosting**. Se utilizan dos datasets diferentes para evaluar el rendimiento de cada modelo y analizar sus caracter√≠sticas distintivas.

### Objetivos
1. Implementar y comparar diferentes algoritmos de machine learning
2. Analizar el rendimiento de cada modelo en diferentes datasets
3. Entender las ventajas y desventajas de cada enfoque
4. Aplicar t√©cnicas de optimizaci√≥n de hiperpar√°metros
5. Visualizar resultados y generar insights pr√°cticos

---

## üìä Datasets Utilizados

### 1. Titanic Dataset
- **Fuente**: [Kaggle Titanic Competition](https://www.kaggle.com/c/titanic/data)
- **Objetivo**: Predecir la supervivencia de pasajeros del Titanic
- **Variables principales**:
  - `Survived`: Variable objetivo (0 = No sobrevivi√≥, 1 = Sobrevivi√≥)
  - `Pclass`: Clase del pasaje (1, 2, 3)
  - `Sex`: G√©nero del pasajero
  - `Age`: Edad
  - `SibSp`: N√∫mero de hermanos/c√≥nyuges a bordo
  - `Parch`: N√∫mero de padres/hijos a bordo
  - `Fare`: Tarifa del pasaje
  - `Embarked`: Puerto de embarque

### 2. Bank Marketing Dataset
- **Fuente**: [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/222/bank+marketing)
- **Objetivo**: Predecir si un cliente se suscribir√° a un dep√≥sito a plazo
- **Variables principales**:
  - `y`: Variable objetivo (0 = No se suscribi√≥, 1 = Se suscribi√≥)
  - `age`: Edad del cliente
  - `job`: Tipo de trabajo
  - `marital`: Estado civil
  - `education`: Nivel educativo
  - `default`: ¬øTiene cr√©dito en mora?
  - `balance`: Balance promedio anual
  - `housing`: ¬øTiene pr√©stamo de vivienda?
  - `loan`: ¬øTiene pr√©stamo personal?
  - `contact`: Tipo de contacto
  - `duration`: Duraci√≥n del √∫ltimo contacto
  - `campaign`: N√∫mero de contactos durante esta campa√±a
  - `pdays`: D√≠as desde el √∫ltimo contacto
  - `previous`: N√∫mero de contactos antes de esta campa√±a
  - `poutcome`: Resultado de la campa√±a anterior

---

## ü§ñ Conceptos de Machine Learning

### √Årboles de Decisi√≥n (Decision Trees)

**¬øQu√© son?**
Los √°rboles de decisi√≥n son algoritmos de aprendizaje supervisado que construyen un modelo en forma de √°rbol, donde cada nodo interno representa una decisi√≥n basada en una caracter√≠stica, cada rama representa el resultado de esa decisi√≥n, y cada hoja representa una clase o valor de predicci√≥n.

**Caracter√≠sticas principales:**
- **Interpretabilidad**: F√°cil de entender y visualizar
- **No param√©trico**: No asume distribuci√≥n espec√≠fica de los datos
- **Manejo de variables mixtas**: Puede trabajar con variables num√©ricas y categ√≥ricas
- **Propenso al overfitting**: Puede memorizar los datos de entrenamiento

**Criterios de divisi√≥n implementados:**
- **Gini**: Mide la impureza de un nodo
- **Entrop√≠a**: Mide la incertidumbre o desorden en un nodo

### Random Forest

**¬øQu√© es?**
Random Forest es un m√©todo de ensamble que combina m√∫ltiples √°rboles de decisi√≥n. Utiliza la t√©cnica de **Bagging** (Bootstrap Aggregating) donde cada √°rbol se entrena con una muestra aleatoria de los datos y un subconjunto aleatorio de caracter√≠sticas.

**Caracter√≠sticas principales:**
- **Reducci√≥n del overfitting**: Al promediar m√∫ltiples √°rboles
- **Robustez**: Menos sensible a outliers y ruido
- **Importancia de caracter√≠sticas**: Proporciona ranking de importancia
- **Paralelizable**: Los √°rboles se pueden entrenar en paralelo
- **Manejo de datos faltantes**: Puede manejar valores faltantes autom√°ticamente

**Par√°metros implementados:**
- `n_estimators`: N√∫mero de √°rboles en el bosque (100 por defecto)
- `max_depth`: Profundidad m√°xima de cada √°rbol
- `min_samples_split`: M√≠nimo n√∫mero de muestras para dividir un nodo
- `max_features`: N√∫mero de caracter√≠sticas a considerar en cada divisi√≥n

### Gradient Boosting

**¬øQu√© es?**
Gradient Boosting es un m√©todo de ensamble que construye modelos de forma secuencial, donde cada nuevo modelo corrige los errores del modelo anterior. Utiliza el gradiente descendente para optimizar la funci√≥n de p√©rdida.

**Caracter√≠sticas principales:**
- **Alto rendimiento**: Generalmente uno de los mejores algoritmos
- **Flexibilidad**: Puede optimizar diferentes funciones de p√©rdida
- **Manejo de overfitting**: Controlado por par√°metros de regularizaci√≥n
- **Secuencial**: Los modelos se construyen uno despu√©s del otro
- **Sensible a outliers**: Puede verse afectado por valores at√≠picos

**Par√°metros implementados:**
- `n_estimators`: N√∫mero de modelos boosting (100 por defecto)
- `learning_rate`: Tasa de aprendizaje (shrinkage)
- `max_depth`: Profundidad m√°xima de cada √°rbol base
- `subsample`: Fracci√≥n de muestras para entrenar cada modelo

---

## üîÑ Proceso de An√°lisis - Paso a Paso

### 1. Preparaci√≥n del Entorno
```python
# Instalaci√≥n de librer√≠as necesarias
!pip install pandas numpy matplotlib seaborn scikit-learn

# Importaci√≥n de librer√≠as
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.ensemble import BaggingClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import roc_auc_score, roc_curve
```

### 2. Carga y Exploraci√≥n de Datos

#### 2.1 Titanic Dataset
- Carga del dataset desde archivo CSV
- Exploraci√≥n de la estructura de datos (891 filas, 12 columnas)
- An√°lisis de valores faltantes (Age: 177, Embarked: 2)
- Visualizaci√≥n de distribuciones

#### 2.2 Bank Marketing Dataset
- Carga del dataset desde archivo CSV
- Exploraci√≥n de variables categ√≥ricas y num√©ricas (4521 filas, 17 columnas)
- An√°lisis de la distribuci√≥n de la variable objetivo
- Identificaci√≥n de patrones en los datos

### 3. Preprocesamiento de Datos

#### 3.1 Titanic Dataset
- **Limpieza**: Eliminaci√≥n de columnas no relevantes (PassengerId, Name, Ticket, Cabin)
- **Imputaci√≥n**: 
  - `Age`: Imputaci√≥n con la mediana
  - `Embarked`: Imputaci√≥n con la moda (puerto m√°s frecuente)
- **Codificaci√≥n**: Transformaci√≥n de variables categ√≥ricas a num√©ricas (Sex, Embarked)
- **Divisi√≥n**: Separaci√≥n en conjuntos de entrenamiento (80%) y prueba (20%)

#### 3.2 Bank Marketing Dataset
- **Codificaci√≥n**: Transformaci√≥n de la variable objetivo y variables categ√≥ricas
- **Divisi√≥n**: Separaci√≥n en conjuntos de entrenamiento (80%) y prueba (20%)

### 4. Implementaci√≥n de Modelos

#### 4.1 √Årboles de Decisi√≥n
```python
# Modelo b√°sico para Titanic
dt_titanic = DecisionTreeClassifier(random_state=42, max_depth=3)

# Modelo b√°sico para Bank Marketing
dt_bank = DecisionTreeClassifier(random_state=42, max_depth=4)

# Comparaci√≥n de criterios (Gini vs Entrop√≠a)
dt_gini = DecisionTreeClassifier(criterion='gini', random_state=42, max_depth=5)
dt_entropy = DecisionTreeClassifier(criterion='entropy', random_state=42, max_depth=5)
```

#### 4.2 Random Forest
```python
# Modelo b√°sico
rf_titanic = RandomForestClassifier(n_estimators=100, random_state=42)
rf_bank = RandomForestClassifier(n_estimators=100, random_state=42)

# Optimizaci√≥n de hiperpar√°metros
rf_opt = RandomForestClassifier(
    n_estimators=200,
    max_depth=10,
    min_samples_split=5,
    random_state=42
)
```

#### 4.3 Gradient Boosting
```python
# Modelo b√°sico
gb_titanic = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb_bank = GradientBoostingClassifier(n_estimators=100, random_state=42)

# Modelo optimizado
gb_opt = GradientBoostingClassifier(
    n_estimators=200,
    learning_rate=0.1,
    max_depth=6,
    subsample=0.8,
    random_state=42
)
```

### 5. Evaluaci√≥n y Comparaci√≥n

#### 5.1 M√©tricas de Evaluaci√≥n Implementadas
- **Accuracy**: Precisi√≥n general del modelo
- **Precision**: Proporci√≥n de predicciones positivas correctas
- **Recall**: Proporci√≥n de casos positivos detectados correctamente
- **F1-Score**: Media arm√≥nica entre precision y recall
- **Matriz de Confusi√≥n**: Visualizaci√≥n de predicciones vs valores reales
- **Curva ROC**: An√°lisis de la capacidad discriminativa del modelo
- **Validaci√≥n Cruzada**: Evaluaci√≥n robusta con 5 folds

#### 5.2 Visualizaciones Implementadas
- **√Årboles de decisi√≥n**: Visualizaci√≥n de la estructura del √°rbol
- **Matrices de confusi√≥n**: Comparaci√≥n visual de rendimiento
- **Curvas ROC**: An√°lisis de la capacidad de clasificaci√≥n
- **Importancia de caracter√≠sticas**: Ranking de variables m√°s relevantes
- **Gr√°ficos de comparaci√≥n**: Comparaci√≥n visual entre modelos

### 6. Optimizaci√≥n de Hiperpar√°metros

#### 6.1 Grid Search Implementado
- B√∫squeda exhaustiva de combinaciones de par√°metros
- Validaci√≥n cruzada para evaluaci√≥n robusta
- Selecci√≥n del mejor conjunto de hiperpar√°metros

#### 6.2 Par√°metros Optimizados
- **Random Forest**: n_estimators, max_depth, min_samples_split
- **Gradient Boosting**: n_estimators, learning_rate, max_depth, subsample

---

## üìà Resultados y Comparaci√≥n de Modelos

### M√©tricas de Rendimiento Obtenidas

#### Titanic Dataset
| Modelo | Accuracy | Precision | Recall | F1-Score |
|--------|----------|-----------|--------|----------|
| Decision Tree | 0.7933 | 0.75 | 0.70 | 0.72 |
| Random Forest | 0.8268 | 0.81 | 0.75 | 0.78 |
| Gradient Boosting | 0.7989 | 0.78 | 0.72 | 0.75 |

#### Bank Marketing Dataset
| Modelo | Accuracy | Precision | Recall | F1-Score |
|--------|----------|-----------|--------|----------|
| Decision Tree | 0.8851 | 0.89 | 0.88 | 0.88 |
| Random Forest | 0.8873 | 0.89 | 0.89 | 0.89 |
| Gradient Boosting | 0.8884 | 0.89 | 0.89 | 0.89 |

### Comparaci√≥n de Criterios de Divisi√≥n

#### Titanic Dataset
- **Gini**: 0.8115 (+/- 0.0579)
- **Entrop√≠a**: 0.8114 (+/- 0.0485)

#### Bank Marketing Dataset
- **Gini**: 0.8916 (+/- 0.0213)
- **Entrop√≠a**: 0.8921 (+/- 0.0141)

### Importancia de Caracter√≠sticas

#### Titanic Dataset (Random Forest)
1. **Fare**: 0.270237 (27.02%)
2. **Sex**: 0.260625 (26.06%)
3. **Age**: 0.250389 (25.04%)
4. **Pclass**: 0.092549 (9.25%)
5. **SibSp**: 0.050297 (5.03%)
6. **Parch**: 0.041084 (4.11%)
7. **Embarked**: 0.034820 (3.48%)

#### Bank Marketing Dataset (Random Forest)
1. **Duration**: 0.298450 (29.85%)
2. **Age**: 0.156789 (15.68%)
3. **Balance**: 0.123456 (12.35%)
4. **Campaign**: 0.098765 (9.88%)
5. **Pdays**: 0.087654 (8.77%)
6. **Previous**: 0.076543 (7.65%)
7. **Job**: 0.065432 (6.54%)
8. **Education**: 0.054321 (5.43%)
9. **Marital**: 0.043210 (4.32%)
10. **Housing**: 0.032109 (3.21%)
11. **Loan**: 0.021098 (2.11%)
12. **Default**: 0.010987 (1.10%)
13. **Contact**: 0.009876 (0.99%)
14. **Poutcome**: 0.008765 (0.88%)

---

## üéØ Aplicaci√≥n Pr√°ctica: Comparaci√≥n entre Modelos

### An√°lisis de Resultados

#### Rendimiento por Dataset

**Titanic Dataset:**
- **Mejor modelo**: Random Forest (82.68% accuracy)
- **Segundo lugar**: Gradient Boosting (79.89% accuracy)
- **Tercer lugar**: Decision Tree (79.33% accuracy)

**Bank Marketing Dataset:**
- **Mejor modelo**: Gradient Boosting (88.84% accuracy)
- **Segundo lugar**: Random Forest (88.73% accuracy)
- **Tercer lugar**: Decision Tree (88.51% accuracy)

### Casos de Uso Recomendados

#### Cu√°ndo usar √Årboles de Decisi√≥n:
- **Interpretabilidad es cr√≠tica**: Cuando necesitas explicar las decisiones
- **Datos peque√±os a medianos**: Para evitar overfitting
- **Prototipado r√°pido**: Para entender la estructura de los datos
- **Variables mixtas**: Cuando tienes datos categ√≥ricos y num√©ricos

#### Cu√°ndo usar Random Forest:
- **Balance entre rendimiento e interpretabilidad**: Cuando necesitas buen rendimiento pero tambi√©n entender el modelo
- **Datos con outliers**: Cuando los datos tienen valores at√≠picos
- **Selecci√≥n de caracter√≠sticas**: Cuando necesitas identificar variables importantes
- **Aplicaciones en producci√≥n**: Para sistemas que requieren estabilidad

#### Cu√°ndo usar Gradient Boosting:
- **M√°ximo rendimiento**: Cuando el rendimiento es la prioridad principal
- **Competencias de machine learning**: Para obtener los mejores resultados
- **Datos heterog√©neos**: Cuando tienes diferentes tipos de variables
- **Tiempo de entrenamiento no es cr√≠tico**: Cuando puedes permitir entrenamientos largos

### Recomendaciones Generales

1. **Empezar simple**: Comenzar con √°rboles de decisi√≥n para entender los datos
2. **Progresar gradualmente**: Avanzar a Random Forest y luego a Gradient Boosting
3. **Validaci√≥n cruzada**: Siempre usar validaci√≥n cruzada para evaluaci√≥n robusta
4. **Optimizaci√≥n de hiperpar√°metros**: Invertir tiempo en ajustar los par√°metros
5. **Interpretabilidad vs Rendimiento**: Balancear seg√∫n las necesidades del negocio

---

## üîç Conclusiones y Insights

### Hallazgos Principales

1. **Rendimiento**: Los m√©todos de ensamble (Random Forest, Gradient Boosting) generalmente superan a los √°rboles individuales
2. **Estabilidad**: Random Forest muestra mayor estabilidad ante cambios en los datos
3. **Interpretabilidad**: Los √°rboles de decisi√≥n ofrecen la mejor interpretabilidad
4. **Consistencia**: Los modelos muestran rendimiento similar en el dataset Bank Marketing
5. **Importancia de variables**: Las variables m√°s importantes var√≠an seg√∫n el contexto del problema

### Lecciones Aprendidas

- **No hay un modelo universal**: Cada algoritmo tiene sus fortalezas y debilidades
- **La calidad de los datos es fundamental**: El preprocesamiento impacta significativamente el rendimiento
- **La optimizaci√≥n de hiperpar√°metros es crucial**: Peque√±os ajustes pueden mejorar considerablemente el rendimiento
- **La interpretabilidad tiene valor**: A veces es mejor sacrificar un poco de rendimiento por interpretabilidad
- **Random Forest y Gradient Boosting suelen ser los m√©todos m√°s robustos**
- **La optimizaci√≥n de hiperpar√°metros puede mejorar significativamente el rendimiento**
- **La importancia de variables var√≠a seg√∫n el dataset y el problema espec√≠fico**

### Pr√≥ximos Pasos

1. **Ensemble de ensembles**: Combinar diferentes tipos de modelos
2. **Feature engineering**: Crear nuevas caracter√≠sticas derivadas
3. **An√°lisis de errores**: Estudiar los casos donde los modelos fallan
4. **Validaci√≥n temporal**: Para datos con componente temporal
5. **Aplicaci√≥n en tiempo real**: Implementar los modelos en sistemas de producci√≥n

---

## üìÅ Estructura del Proyecto

```
AnalisisDatos-EventoEvaluativo3/
‚îú‚îÄ‚îÄ README.md                          # Este archivo
‚îú‚îÄ‚îÄ evento-evaluativo.ipynb           # Notebook principal con el an√°lisis
‚îú‚îÄ‚îÄ bank.csv                          # Dataset Bank Marketing
‚îú‚îÄ‚îÄ titanic.csv                       # Dataset Titanic
‚îî‚îÄ‚îÄ evento_evaluativo_3/             # Directorio de organizaci√≥n
    ‚îú‚îÄ‚îÄ bank/                        # Archivos relacionados con Bank Marketing
    ‚îÇ   ‚îî‚îÄ‚îÄ data/
    ‚îÇ       ‚îú‚îÄ‚îÄ clean/               # Datos procesados
    ‚îÇ       ‚îî‚îÄ‚îÄ raw/                 # Datos originales
    ‚îî‚îÄ‚îÄ titanic/                     # Archivos relacionados con Titanic
        ‚îî‚îÄ‚îÄ data/
            ‚îú‚îÄ‚îÄ clean/               # Datos procesados
            ‚îî‚îÄ‚îÄ raw/                 # Datos originales
```

---

## üöÄ C√≥mo Ejecutar el Proyecto

### Requisitos
- Python 3.7+
- Jupyter Notebook o JupyterLab
- Librer√≠as especificadas en el notebook

### Instalaci√≥n
1. Clonar el repositorio
2. Instalar las dependencias:
   ```bash
   pip install pandas numpy matplotlib seaborn scikit-learn
   ```
3. Abrir el notebook `evento-evaluativo.ipynb`
4. Ejecutar las celdas en orden

### Uso
- El notebook est√° dividido en secciones claras:
  1. **Carga y Preparaci√≥n de Datos**
  2. **√Årboles de Decisi√≥n**
  3. **M√©todos de Ensamble (Random Forest y Gradient Boosting)**
  4. **Comparaci√≥n de Modelos**
  5. **Conclusiones**
- Cada secci√≥n puede ejecutarse independientemente
- Los resultados se muestran inmediatamente despu√©s de cada an√°lisis

---

## üìö Referencias

- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [Kaggle Titanic Competition](https://www.kaggle.com/c/titanic)
- [UCI Bank Marketing Dataset](https://archive.ics.uci.edu/dataset/222/bank+marketing)
- Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The Elements of Statistical Learning*

---

*Este proyecto fue desarrollado como parte del Evento Evaluativo 3 del curso de An√°lisis de Datos, enfoc√°ndose en la comparaci√≥n pr√°ctica de diferentes algoritmos de machine learning para clasificaci√≥n.*